import sys
import requests
import socket
import time
import concurrent.futures
import re
import statistics
import os
import json
import subprocess
import geoip2.database 
from datetime import datetime, timedelta, timezone
from urllib.parse import unquote, quote, parse_qs

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
GENERAL_URLS = [
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/main/BLACK_VLESS_RUS.txt",
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/main/configs/vless.txt",
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/refs/heads/main/BLACK_SS+All_RUS.txt",
    "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/1.txt",
    "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/6.txt",
    "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/22.txt",
    "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/23.txt",
    "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/24.txt",
    "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/25.txt"
]

WHITELIST_URLS = [
    "https://raw.githubusercontent.com/igareck/vpn-configs-for-russia/main/Vless-Reality-White-Lists-Rus-Mobile.txt"
]

MMDB_URL = "https://github.com/P3TERX/GeoLite.mmdb/raw/download/GeoLite2-Country.mmdb"
MMDB_FILE = "Country.mmdb"
XRAY_BIN = "./xray" 

# --- –ü–ê–†–ê–ú–ï–¢–†–´ –û–¢–ë–û–†–ê ---
TARGET_GAME = 1       
TARGET_UNIVERSAL = 3  
TARGET_WARP = 2       
TARGET_WHITELIST = 2  

# –¢–∞–π–º–∞—É—Ç—ã —Å—Ç–∞–ª–∏ –∂–µ—Å—Ç—á–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
TCP_TIMEOUT = 0.5 
REAL_TEST_TIMEOUT = 4.0

OUTPUT_FILE = 'FL1PVPN'
JSON_FILE = 'stats.json'

BANNED_COUNTRIES = ['CN', 'IR', 'KP'] 

PING_BASE_MS = {
    'RU': 25, 'FI': 40, 'EE': 45, 'SE': 55, 'DE': 65, 'NL': 70, 
    'FR': 75, 'GB': 80, 'PL': 60, 'KZ': 60, 'UA': 50, 'US': 150
}

RUS_NAMES = {
    'US': '–°–®–ê', 'DE': '–ì–µ—Ä–º–∞–Ω–∏—è', 'NL': '–ù–∏–¥–µ—Ä–ª–∞–Ω–¥—ã', 'FI': '–§–∏–Ω–ª—è–Ω–¥–∏—è', 
    'RU': '–†–æ—Å—Å–∏—è', 'TR': '–¢—É—Ä—Ü–∏—è', 'GB': '–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è', 'FR': '–§—Ä–∞–Ω—Ü–∏—è', 
    'SE': '–®–≤–µ—Ü–∏—è', 'PL': '–ü–æ–ª—å—à–∞', 'UA': '–£–∫—Ä–∞–∏–Ω–∞', 'KZ': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω',
    'EE': '–≠—Å—Ç–æ–Ω–∏—è', 'LV': '–õ–∞—Ç–≤–∏—è', 'LT': '–õ–∏—Ç–≤–∞', 'AT': '–ê–≤—Å—Ç—Ä–∏—è',
    'CZ': '–ß–µ—Ö–∏—è', 'BG': '–ë–æ–ª–≥–∞—Ä–∏—è', 'IT': '–ò—Ç–∞–ª–∏—è', 'ES': '–ò—Å–ø–∞–Ω–∏—è'
}

geo_reader = None

def download_mmdb():
    if not os.path.exists(MMDB_FILE):
        try:
            r = requests.get(MMDB_URL, stream=True)
            with open(MMDB_FILE, 'wb') as f:
                for chunk in r.iter_content(1024): f.write(chunk)
        except: pass

def init_geoip():
    global geo_reader
    try: geo_reader = geoip2.database.Reader(MMDB_FILE)
    except: pass

def get_ip_country(ip):
    if not geo_reader: return 'XX'
    try: return geo_reader.country(ip).country.iso_code
    except: return 'XX'

def extract_links(text):
    return re.findall(r"(vless://[a-zA-Z0-9\-@:?=&%.#_]+)", text)

def parse_vless(link, source_type):
    try:
        part = link.split("@")[1].split("?")[0]
        if ":" in part:
            host, port = part.split(":")
        else:
            return None
            
        query = link.split("?")[1].split("#")[0]
        params = parse_qs(query)
        
        return {
            "ip": host, "port": int(port), "original": link,
            "uuid": link.split("@")[0].replace("vless://", ""),
            "transport": params.get('type', ['tcp'])[0],
            "security": params.get('security', ['none'])[0],
            "flow": params.get('flow', [''])[0],
            "sni": params.get('sni', [''])[0],
            "fp": params.get('fp', ['chrome'])[0],
            "path": params.get('path', ['/'])[0],
            "pbk": params.get('pbk', [''])[0],
            "sid": params.get('sid', [''])[0],
            "source_type": source_type,
            "latency": 9999, "real_delay": 9999
        }
    except: return None

def tcp_ping(host, port):
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(TCP_TIMEOUT)
        start = time.perf_counter()
        if sock.connect_ex((host, port)) == 0:
            return (time.perf_counter() - start) * 1000
        sock.close()
    except: pass
    return None

def generate_xray_config(server, local_port):
    outbound = {
        "protocol": "vless",
        "settings": {
            "vnext": [{
                "address": server['ip'],
                "port": server['port'],
                "users": [{"id": server['uuid'], "encryption": "none", "flow": server['flow']}]
            }]
        },
        "streamSettings": {
            "network": server['transport'],
            "security": server['security'],
        }
    }
    
    s = outbound["streamSettings"]
    if server['security'] == 'reality':
        s['realitySettings'] = {
            "publicKey": server['pbk'], "shortId": server['sid'], 
            "serverName": server['sni'], "fingerprint": server['fp']
        }
    elif server['security'] == 'tls':
        s['tlsSettings'] = {"serverName": server['sni'], "fingerprint": server['fp']}
        
    if server['transport'] == 'ws':
        s['wsSettings'] = {"path": server['path'], "headers": {"Host": server['sni']}}
    elif server['transport'] == 'grpc':
        s['grpcSettings'] = {"serviceName": server['path']}

    config = {
        "log": {"loglevel": "none"}, # –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        "inbounds": [{"port": local_port, "listen": "127.0.0.1", "protocol": "socks", "settings": {"udp": True}}],
        "outbounds": [outbound]
    }
    return config

# –§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
def check_real_server_wrapper(args):
    server, unique_id = args
    local_port = 10000 + unique_id
    
    conf_name = f"config_{local_port}.json"
    config = generate_xray_config(server, local_port)
    
    with open(conf_name, 'w') as f: json.dump(config, f)
    
    proc = subprocess.Popen([XRAY_BIN, "-c", conf_name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    time.sleep(0.4) # –ß—É—Ç—å —É–º–µ–Ω—å—à–∏–ª–∏ –≤—Ä–µ–º—è –Ω–∞ —Å—Ç–∞—Ä—Ç
    
    success = False
    delay = 9999
    
    try:
        proxies = {'http': f'socks5://127.0.0.1:{local_port}', 'https': f'socks5://127.0.0.1:{local_port}'}
        start = time.perf_counter()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–π–º–∞—É—Ç 4 —Å–µ–∫ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        r = requests.get('http://cp.cloudflare.com/', proxies=proxies, timeout=REAL_TEST_TIMEOUT)
        if r.status_code == 204 or r.status_code == 200:
            delay = (time.perf_counter() - start) * 1000
            success = True
    except: pass
    finally:
        proc.terminate()
        try: os.remove(conf_name)
        except: pass
        
    if success:
        return True, delay, server
    return False, 9999, server

def process_batch(servers):
    valid = []
    for s in servers:
        s['country'] = get_ip_country(s['ip'])
        if s['country'] in BANNED_COUNTRIES: continue
        
        p = tcp_ping(s['ip'], s['port'])
        if p:
            s['latency'] = int(p)
            valid.append(s)
    return valid

def run_tournament(candidates, needed, title):
    if not candidates: return []
    
    # –ë–µ—Ä–µ–º –¢–û–ü-30 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ TCP (–±–æ–ª—å—à–µ –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
    candidates.sort(key=lambda x: x['latency'])
    semi_finalists = candidates[:30]
    
    print(f"\nüèüÔ∏è {title} (Parallel checking {len(semi_finalists)} candidates)...")
    
    real_winners = []
    
    # –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö XRAY
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º 8 –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è Xray (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è 2-core CPU –Ω–∞ GitHub)
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        # –ü–µ—Ä–µ–¥–∞–µ–º (—Å–µ—Ä–≤–µ—Ä, —É–Ω–∏–∫–∞–ª—å–Ω—ã–π_id) —á—Ç–æ–±—ã –ø–æ—Ä—Ç—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å
        tasks = [(s, i) for i, s in enumerate(semi_finalists)]
        results = list(executor.map(check_real_server_wrapper, tasks))
        
        for success, delay, s in results:
            if success:
                s['real_delay'] = int(delay)
                # –®—Ç—Ä–∞—Ñ Universal —Å–µ—Ä–≤–µ—Ä–∞–º –∏–∑ –°–ù–ì (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–±–∏–≤–∞–ª–∏ –ï–≤—Ä–æ–ø—É –ø–∏–Ω–≥–æ–º)
                tier_penalty = 0
                if title == "UNIVERSAL CUP" and s['country'] in ['RU', 'KZ', 'UA', 'BY']:
                    tier_penalty = 1000 
                
                s['score'] = s['real_delay'] + tier_penalty
                print(f"   ‚úÖ {s['country']} | TCP: {s['latency']}ms | REAL: {int(delay)}ms")
                real_winners.append(s)
            else:
                print(f"   ‚ùå {s['country']} | TCP: {s['latency']}ms | REAL: FAIL")

    real_winners.sort(key=lambda x: x['score'])
    return real_winners[:needed]

def main():
    print("--- STARTING V70 (TURBO XRAY) ---")
    download_mmdb()
    init_geoip()
    
    # 1. –°–ë–û–† –°–°–´–õ–û–ö (–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    all_raw = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as ex:
        f1 = ex.submit(lambda: [parse_vless(l, 'gen') for u in GENERAL_URLS for l in extract_links(requests.get(u, timeout=5).text)])
        f2 = ex.submit(lambda: [parse_vless(l, 'white') for u in WHITELIST_URLS for l in extract_links(requests.get(u, timeout=5).text)])
        try:
            all_raw = [x for x in (f1.result() + f2.result()) if x]
        except:
            print("Error downloading sources")
            return

    unique = list({s['original']: s for s in all_raw}.values())
    print(f"Total Unique Configs: {len(unique)}")
    
    # 2. –ú–ê–°–°–û–í–´–ô TCP –ü–ò–ù–ì (100 –ø–æ—Ç–æ–∫–æ–≤ - –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è IO –æ–ø–µ—Ä–∞—Ü–∏–π)
    tcp_survivors = []
    print("üöÄ Mass TCP Pinging...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as ex:
        chunk_size = 50
        chunks = [unique[i:i + chunk_size] for i in range(0, len(unique), chunk_size)]
        for res in ex.map(process_batch, chunks):
            tcp_survivors.extend(res)
            
    print(f"TCP Survivors: {len(tcp_survivors)}")
    
    gaming_pool = [s for s in tcp_survivors if s['country'] in ['FI','SE','EE','DE','NL'] and s['latency'] < 80]
    universal_pool = [s for s in tcp_survivors if s['source_type'] == 'gen']
    whitelist_pool = [s for s in tcp_survivors if s['source_type'] == 'white' or s['country'] == 'RU']
    
    final_list = []
    
    # 3. –§–ò–ù–ê–õ–´ (–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π Xray)
    final_list.extend(run_tournament(gaming_pool, TARGET_GAME, "GAME CUP"))
    final_list.extend(run_tournament(universal_pool, TARGET_UNIVERSAL, "UNIVERSAL CUP"))
    final_list.extend(run_tournament(whitelist_pool, TARGET_WHITELIST, "WHITELIST CUP"))
    
    # 4. –°–û–•–†–ê–ù–ï–ù–ò–ï
    utc_now = datetime.now(timezone.utc)
    msk_now = utc_now + timedelta(hours=3)
    
    json_data = {"updated_at": msk_now.strftime('%H:%M'), "servers": []}
    result_links = [f"vless://fake@1.1.1.1:80?#{quote(f'–û–±–Ω–æ–≤–ª–µ–Ω–æ: {msk_now.strftime('%H:%M')}')}"]
    
    for s in final_list:
        flag = "".join([chr(127397 + ord(c)) for c in s['country'].upper()])
        name_c = RUS_NAMES.get(s['country'], s['country'])
        
        cat = "UNIVERSAL"
        if s in gaming_pool and s['score'] < 100: cat = "GAMING"
        if s['country'] == 'RU': cat = "WHITELIST"
        
        label = f"‚ö° {flag} {name_c} | {s['real_delay']}ms"
        if cat == 'GAMING': label = f"üéÆ {flag} {name_c} | {s['real_delay']}ms"
        if cat == 'WHITELIST': label = f"‚ö™ {flag} {name_c} | {s['real_delay']}ms"
        
        final_link = f"{s['original'].split('#')[0]}#{quote(label)}"
        result_links.append(final_link)
        
        json_data["servers"].append({
            "name": label, "country": name_c, "iso": s['country'],
            "ping": s['real_delay'], "ip": s['ip'], "link": final_link,
            "category": cat, "protocol": s['transport'].upper(), "type": "VLESS"
        })
        
    with open(OUTPUT_FILE, 'w') as f:
        f.write(base64.b64encode("\n".join(result_links).encode('utf-8')).decode('utf-8'))
    with open(JSON_FILE, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
        
    print(f"DONE. Saved {len(final_list)} verified servers.")

if __name__ == "__main__":
    main()
